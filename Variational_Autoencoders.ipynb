{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets,transforms\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Converts the pixel values in the image in the range -1 to 1\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./test_data', train=False,download=True,transform=transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_data,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Img -> Hiddden dim -> mean, std -> Parameterization Trick -> Decoder -> Output Img\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.common_fc = nn.Sequential(\n",
    "            nn.Linear(28*28,196),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(196,48),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.mean_fc = nn.Sequential(\n",
    "            nn.Linear(48,16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16,2)\n",
    "        )\n",
    "        # Here we are calculating the log variance not the actual variance in the distribution\n",
    "        self.log_var_fc = nn.Sequential(\n",
    "            nn.Linear(48,16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16,2)\n",
    "        )\n",
    "\n",
    "        self.decoder_fcs = nn.Sequential(\n",
    "            nn.Linear(2,16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16,48),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(48,196),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(196,28*28)\n",
    "        )\n",
    "    def encode(self,x):\n",
    "        out = self.common_fc(torch.flatten(x,start_dim=1))\n",
    "        mean = self.mean_fc(out)\n",
    "        log_var = self.log_var_fc(out)\n",
    "        return mean,log_var\n",
    "    \n",
    "\n",
    "    # Here we are applying the reparametrization trick\n",
    "    def sample(self,mean,log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        z = torch.randn_like(std)\n",
    "        z = z*std + mean\n",
    "        return z\n",
    "    \n",
    "    def decode(self,z):\n",
    "        out = self.decoder_fcs(z)\n",
    "        out = out.reshape((z.size(0),1,28,28))\n",
    "        return out\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # Batch,Channel,Height,Width\n",
    "        ## Encoder\n",
    "        mean,log_var = self.encode(x)\n",
    "        ## Sampling\n",
    "        z = self.sample(mean,log_var)\n",
    "        ## Decoder\n",
    "        output = self.decode(z)\n",
    "        return mean, log_var, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Instantiate the model\n",
    "    model = VAE().to(device=device)\n",
    "    # Training Parameters\n",
    "    num_epochs = 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    recon_losses = []\n",
    "    kl_losses = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        for im,_ in tqdm(data_loader):\n",
    "            im = im.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            mean, log_var, out = model(im)\n",
    "            cv2.imwrite('./vae_outputs/input.jpeg',255*((im+1)/2).detach().cpu().numpy()[0,0])\n",
    "            cv2.imwrite('./vae_outputs/output.jpeg',255*((out+1)/2).detach().cpu().numpy()[0,0])\n",
    "\n",
    "            kl_loss = torch.mean(0.5*(torch.sum(torch.exp(log_var) + mean **2 -1 - log_var,dim = -1)))\n",
    "            recon_loss = criterion(out,im)\n",
    "            loss = recon_loss+0.00001*kl_loss\n",
    "            recon_losses.append(recon_loss.item())\n",
    "            losses.append(loss.item())\n",
    "            kl_losses.append(kl_loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Finished Epoch: {epoch_idx+1}|Reconstruction Loss: {np.mean(recon_losses):.4f}|KL Loss:{np.mean(kl_losses):4f}|')\n",
    "\n",
    "    # Run a reconstruction for some sample test images\n",
    "    idxs = torch.randint(0,len(test_data)-1,(100,))\n",
    "    ims = torch.cat([test_data[idx][0][None,:] for idx in idxs]).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
